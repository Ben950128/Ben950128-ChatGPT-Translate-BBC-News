{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import uuid\n",
    "import psycopg\n",
    "import requests\n",
    "import json\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from elasticsearch import Elasticsearch\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from datetime import date"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用連OPENAI套件連API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_gpt_api(prompt: str)-> str:\n",
    "    openai.api_key = os.getenv(\"CHATGPT_KEY\")\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用requests連接API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_gpt_api(prompt: str)-> str:\n",
    "    url = \"https://api.openai.com/v1/chat/completions\"\n",
    "    api_key = os.getenv(\"CHATGPT_KEY\")\n",
    "    headers = {\"Authorization\": \"Bearer \"+ api_key}\n",
    "    data = {\"model\": \"gpt-3.5-turbo\",\"messages\": [{\"role\": \"user\", \"content\": prompt}]}\n",
    "    response = requests.post(url, headers=headers, json=data).text\n",
    "    print(json.loads(response))\n",
    "    return json.loads(response)[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = \"flask\"\n",
    "print(connect_gpt_api(f\"早安，請簡單介紹{news}\"))\n",
    "news = \"Djangle\"\n",
    "print(connect_gpt_api(f\"早安，請簡單介紹{news}\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 非同步連接API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch(session, url, headers, data):\n",
    "    async with session.post(url, headers=headers, json=data) as response:\n",
    "        return await response.text()\n",
    "\n",
    "async def main(prompts):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        url = \"https://api.openai.com/v1/chat/completions\"\n",
    "        api_key = os.getenv(\"CHATGPT_KEY\")\n",
    "        headers = {\"Authorization\": \"Bearer \"+ api_key}\n",
    "        tasks = []\n",
    "\t\t# 將coroutine包進去tasks裡面\n",
    "        for prompt in prompts:\n",
    "            data = {\"model\": \"gpt-3.5-turbo\",\"messages\": [{\"role\": \"user\", \"content\": prompt}]}\n",
    "            tasks.append(fetch(session, url, headers, data))\n",
    "            print(data)\n",
    "\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        for result in results:\n",
    "            print(json.loads(result)[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "# asyncio.run(main())\n",
    "prompts = [\"早安，請簡單介紹flask\", \"早安，請簡單介紹Djangle\"]\n",
    "await main(prompts)    # jupyter中使用"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 爬取BBC新聞的URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "news_set = {\n",
    "    \"world\": [], \n",
    "    \"business\": [], \n",
    "    \"technology\": [], \n",
    "    \"science_and_environment\": [], \n",
    "    \"stories\": [], \n",
    "    \"entertainment_and_arts\": [], \n",
    "    \"health\": []\n",
    "}\n",
    "news_temp_set = set()\n",
    "for news_type in news_set.keys():\n",
    "    driver.get(\"https://www.bbc.com/news/\" + news_type)\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    title_tags = soup.select(\"a.gs-c-promo-heading\")\n",
    "    for title_tag in title_tags:\n",
    "        if \"news\" in title_tag[\"href\"] and \"http\" not in title_tag[\"href\"] and title_tag[\"href\"] not in news_temp_set:\n",
    "            news_set[news_type].append(title_tag[\"href\"])\n",
    "            news_temp_set.add(title_tag[\"href\"])\n",
    "            \n",
    "    print(news_type)\n",
    "print(news_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 爬取BBC文章內容，並insert進postgresql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg.connect(os.getenv(\"DATABASE_CONFIG\"))\n",
    "cursor = conn.cursor()\n",
    "base_url = \"https://www.bbc.com\"\n",
    "for key in news_set.keys():\n",
    "    num = 0\n",
    "    for sub_url in news_set[key]:\n",
    "        driver.get(base_url + sub_url)\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        article = soup.select(\"article\")\n",
    "        try:\n",
    "            # 網址有可能是新聞影片\n",
    "            header = article[0].select(\"header > h1\")[0].text\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            contents = article[0].select(\"div[data-component='text-block']\")\n",
    "            news = \" \".join([content.text for content in contents])\n",
    "            # 控制新聞字數在800字內\n",
    "            if len(news.split()) < 800:\n",
    "                num += 1\n",
    "                news_origin = connect_gpt_api(f\"將以下文章分段，請用英文回傳:\\n{news}\")\n",
    "                news_tw = connect_gpt_api(f\"翻譯以下文章並分段，請用繁體中文回傳:\\n{news}\")\n",
    "                toeic_500 = connect_gpt_api(f\"請用多益500的程度將文章改寫並分段，盡量不要刪減文章原意，請用英文回傳:\\n{news}\")\n",
    "                toeic_700 = connect_gpt_api(f\"請用多益700的程度將文章改寫並分段，盡量不要刪減文章原意，請用英文回傳:\\n{news}\")\n",
    "                cursor.execute(f\"\"\"\n",
    "                    INSERT INTO bbc_news.bbc_news \n",
    "                    (\"news_id\", \"type\", \"title\", \"news_origin\", \"news_tw\", \"toeic_500\", \"toeic_700\", \"date\") VALUES \n",
    "                    (%(id)s, %(type)s, %(title)s, %(news_origin)s, %(news_tw)s, %(toeic_500)s, %(toeic_700)s, %(today)s)\n",
    "                \"\"\", {\n",
    "                    \"id\": str(uuid.uuid4()),\n",
    "                    \"type\": key,\n",
    "                    \"title\": header,\n",
    "                    \"news_origin\": news_origin,\n",
    "                    \"news_tw\": news_tw,\n",
    "                    \"toeic_500\": toeic_500,\n",
    "                    \"toeic_700\": toeic_700,\n",
    "                    \"today\": str(date.today())\n",
    "                })\n",
    "                conn.commit()\n",
    "                print(key)\n",
    "                # 每個主題的新聞只insert 1個\n",
    "                if num == 1:\n",
    "                    break\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 爬取BBC文章內容，並insert進elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usename = os.getenv(\"ELASTICSEARCH_USERNAME\")\n",
    "password = os.getenv(\"ELASTICSEARCH_PASSWORD\")\n",
    "elastic_host = os.getenv(\"ELASTICSEARCH_HOST\")\n",
    "es = Elasticsearch(hosts=elastic_host, basic_auth=(usename, password))\n",
    "base_url = \"https://www.bbc.com\"\n",
    "for key in news_set.keys():\n",
    "    num = 0\n",
    "    for sub_url in news_set[key]:\n",
    "        driver.get(base_url + sub_url)\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        article = soup.select(\"article\")\n",
    "        try:\n",
    "            # 網址有可能是新聞影片\n",
    "            header = article[0].select(\"header > h1\")[0].text\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            contents = article[0].select(\"div[data-component='text-block']\")\n",
    "            news = \" \".join([content.text for content in contents])\n",
    "            # 控制新聞字數在800字內\n",
    "            if len(news.split()) < 800:\n",
    "                num += 1\n",
    "                news_tw = connect_gpt_api(f\"翻譯以下文章，並用繁體中文回傳:\\n{news}\")\n",
    "                es.index(\n",
    "                    index=\"bbc_news\",\n",
    "                    id=str(uuid.uuid4()),\n",
    "                    document={\n",
    "                        \"type\": key,\n",
    "                        \"title\": header,\n",
    "                        \"content\": news,\n",
    "                        \"zh_tw\": news_tw,\n",
    "                        \"date\": str(date.today())\n",
    "                    }\n",
    "                )\n",
    "                print(key)\n",
    "                # 每個主題的新聞只insert 1個\n",
    "                if num == 1:\n",
    "                    break\n",
    "es.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
